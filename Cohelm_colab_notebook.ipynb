{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLBfgrpqE0gH"
      },
      "source": [
        "# How to run the notebook\n",
        "\n",
        "I developedd this on a V100.\n",
        "\n",
        "Run the first cell that install the dependancies, then restart the runtime with runtime > restart runtime. This is necessary on colab because of the accellerate package.\n",
        "\n",
        "After it restarted, run all cells excluding the one you already ran.\n",
        "\n",
        "The results object should be logged at the end."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2byrEkPM8zVK"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "!pip install transformers\n",
        "\n",
        "!pip install torch\n",
        "\n",
        "!pip install langchain\n",
        "!pip install -i https://test.pypi.org/simple/ bitsandbytes\n",
        "!pip install accelerate\n",
        "\n",
        "!pip install einops\n",
        "\n",
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4qGy4rPeRhBO",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Medical record\n",
        "medical_text = \"\"\"\n",
        "Medical Record\n",
        "Pa#ent Name: John Smith\n",
        "DOB: 06/16/1982\n",
        "MRN: 456789123\n",
        "Sex: Male\n",
        "Chief Complaint\n",
        "hemorrhoids, new patient\n",
        "Pa/ent’s Care Team\n",
        "Primary Care Provider: Name: Care Provider MD Address: 123 Main Street, Cocoa, FL 12345 Phone: (123) 456-\n",
        "7899 Fax: (123) 456-7899 NPI: 1234567899\n",
        "Sports Medicine: Name: Sports Medicine Address: 123 Main Street, Cocoa, FL 12345 Phone: (123) 456-7899\n",
        "Fax: (123) 456-7899 NPI: 1234567899\n",
        "Patient’s Pharmacies\n",
        "Pharmacy: Name: Pharmacy Address: 123 Main Street, Cocoa, FL 12345 Phone: (123) 456-7899 Fax: (123) 456-\n",
        "7899\n",
        "Vitals\n",
        "Ht: 6 P 2 in\n",
        "Wt: 165 lbs\n",
        "BMI: 21.2\n",
        "Pulse: 96 bpm\n",
        "RR: 16\n",
        "02Sat: 87%\n",
        "Allergies\n",
        "• Allergies not reviewed (last reviewed 11/28/2022)\n",
        "• NKDA\n",
        "Medica/ons\n",
        "• Clenpiq 10 rng-3.5 gram-12 gram/160 ml oral solution Take 320 ml by oral route as directed\n",
        "• diclofenac 1 % topical gel BMI: 21.2 02Sat: 87% 02/10/23 prescribad 11 /28/22 filled · APPLY 2 GRAMS\n",
        "TO THE AFFECTED AREA(S) TOPICALLY FOUR TIMES A DAY\n",
        "• meloxicarn 15 mg tablet TAKE ONE TABLET BY MOUTH ONE TIME DAILY\n",
        "Problems\n",
        "Reviewed Problems · No known problems\n",
        "Family History\n",
        "Family History not reviewed (last reviewed 11/28/2022)\n",
        "Mother\n",
        "- Arthritis\n",
        "- Hypertensive disorder\n",
        "- Hypercholesterolemia\n",
        "Father\n",
        "- Hypertensive disorder\n",
        "- Congestive heart failure\n",
        "- Dlabatas mallitus\n",
        "\n",
        "- Chronic obstructive lung disease\n",
        "- Arthritis\n",
        "- Heart disease\n",
        "Brother\n",
        "- Congestive heart failure\n",
        "- Asthma\n",
        "Social History\n",
        "Social History not reviewed (last reviewed 11/28/2022)\n",
        "Ac#vi#es of Dally Living\n",
        "Are you deaf or do you have serious difficulty hearing?: No\n",
        "Are you able to walk?: Yes: walks without restric@ons\n",
        "Do you have transporta@on difficul@es?: No\n",
        "Diet and Exercise\n",
        "What type of diet are you following?: Regular\n",
        "What Is your exercise level?: None\n",
        "Educa#on and Occupa#on\n",
        "What is the highest grade or level of school you have completed or the highest degree you have received?:\n",
        "High school graduate\n",
        "Are you currently employed?: Yes\n",
        "What Is your occupation?: Lineman\n",
        "Advance Directive\n",
        "Do you have a medical power of attorney?: No\n",
        "Is blood transfusion acceptable in an emergency?: Yes\n",
        "Substance Use\n",
        "Do you or have you eversmoked tobacco?: Currant every day smoker\n",
        "How much tobacco do you chew?; none\n",
        "At what age did you start smoking tobacco?: 20\n",
        "How much tobacco do you smoke?: 1 pack per day\n",
        "How many years have you smoked tobacco?: 20\n",
        "What is your level of alcohol consump@on?: None\n",
        "How many years have you consumed alcohol?: 20\n",
        "What is your level of caffeine consump@on?: Occasional\n",
        "Marriage and Sexuality\n",
        "What is yourrela@onship status?: Married\n",
        "Are you sexually ac@ve?: Yes\n",
        "Do you use protec@on during sex?: No\n",
        "How many children do you have?: 3\n",
        "Home and Environment\n",
        "Do you have any pets?: Yes\n",
        "Are you passively exposed to smoke?: Yes\n",
        "Lifestyle\n",
        "Do you feel stressed (tense, restless, nervous, or anxious, or unable to sleep at night)?: Not at all\n",
        "Do you use your seat belt or car seat rou@nely?: No\n",
        "PMG Social History\n",
        "Do you have a supportsystem?: Yes\n",
        "Domes@c violence history: No\n",
        "\n",
        "Contracep@on used: Vasectomy\n",
        "Other tobacco products: None\n",
        "Living will: No\n",
        "Educa@on specifics: Public school\n",
        "Home health; No\n",
        "Received rabies vaccine in 2002 - travelled to Namibia\n",
        "Gender Iden#ty and LGBTQ\n",
        "Iden@ty GenderIden@ty: Choose not to disclose\n",
        "First name used: John\n",
        "Sexual orienta@on: Choose not to disclose\n",
        "Surgical History\n",
        "Surgical History not reviewed (last reviewed 11/28/2022)\n",
        "Past Medical History\n",
        "Patient diagnosed with haemorrhoids in 2009, treated with hydrocortisone cream, and fully resolved\n",
        "\n",
        "H P I\n",
        "Pa@ent is a 41 y/o male with history of lateral epicondyli@s who isseen for the first @me at this prac@ce.\n",
        "Pa@ent never had a colonoscopy. Pa@ent is complaining ofsymptoma@c haemorrhoidstwo months ago, one of\n",
        "which had ruptured and bled last year. Pa@ent hasfamily history of colon cancer (grandfather on his eigh@es).\n",
        "Pa@ent denies blood in stool.\n",
        "ROS\n",
        "ROS as noted in the HPJ\n",
        "Physical Exam\n",
        "Cons#tu#onal: General Appearance: healthy-appearing, well-nourished, and well-developed. Level of Distress:\n",
        "NAO. Ambula@on: ambula@ng normally.\n",
        "Psychiatric: Insight: good Judgement. Mental Status: ac@ve and alert. Orienta@on: to @me, place, and person.\n",
        "Memory: recent memory normal.\n",
        "Abdomen: Bowel Sounds: normal. Inspec@on and Palpa@on: no tenderness, guarding, masses, rebound\n",
        "tenderness, or CVA tenderness and soP and non-distended. Liver: non-tender and no hepatomegaly. Spleen:\n",
        "non-tender and no splenomegaly. Hernia: none palpable.\n",
        "Assessment/ Plan\n",
        "1. Haemorrhoids\n",
        "Pa@ent is asymptoma@c right know. I advised to seek evalua@on for banding procedure aPer colonoscopy\n",
        "(depending on evalua@on done)\n",
        "K64.9: Unspecified haemorrhoids.\n",
        "2. Screening for malignant neoplasm of colon\n",
        "Pa@ent will have colonoscopy with average risk. Consentsigned. Risks associated with this procedure such as\n",
        "bleeding, Infec@on and perfora@on were discussed with the pa@ent.\n",
        "Z12.11: Encounter for screening for malignant neoplasm of colon\n",
        "• Clenpiq 10 mg-3.5 gram-12 gram/160 ml oral solu#on - Take 320 ml by oral route as directed Qty:\n",
        "(320) ml Refills: 0\n",
        "3. Family history of cancer of colon-\n",
        "\n",
        "Pa@ent has family history of colon cancer (grandfather on his eigh@es) Z80.0: Family history of malignant\n",
        "neoplasm of diges@ve organs\n",
        "Haematochezia\n",
        "4. Pa@ent has BRBPR last year\n",
        "K92.1: Melena\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wIUTefcmZSc6",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Data model\n",
        "import json\n",
        "from jsonschema import validate\n",
        "\n",
        "question_schema = {\n",
        "  \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n",
        "  \"type\": \"object\",\n",
        "  \"version\": \"1.0.0\",\n",
        "  \"properties\": {\n",
        "    \"question\": {\"type\": \"string\"},\n",
        "    \"answer\": {\"type\": \"string\"},\n",
        "    \"justification\": {\"type\": \"string\"},\n",
        "    \"confidence_score\": {\"type\": \"integer\"}\n",
        "  },\n",
        "  \"required\": [\"question\", \"answer\", \"justification\", \"confidence_score\"],\n",
        "}\n",
        "\n",
        "schema = {\n",
        "    \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n",
        "    \"type\": \"object\",\n",
        "    \"version\": \"1.0.0\",\n",
        "    \"properties\": {\n",
        "        \"general_info\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"chief_complaint\": {\"type\": \"string\"},\n",
        "                \"allergies\": {\"type\": \"string\"},\n",
        "                \"preexisting_medications\": {\n",
        "                    \"type\": \"string\",\n",
        "                },\n",
        "                \"meta\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"risk_profile\": {\"type\": \"string\"},\n",
        "                        \"treatment_assessment\": {\"type\": \"string\"}\n",
        "                    },\n",
        "                    \"required\": [\"risk_profile\", \"treatment_assessment\"]\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"chief_complaint\", \"treatment_plan\", \"allergies\", \"preexisting_medications\", \"meta\"]\n",
        "        },\n",
        "        \"questions\": {\n",
        "            \"type\": \"array\",\n",
        "            \"items\": question_schema\n",
        "        },\n",
        "    },\n",
        "    \"required\": [\"general_info\", \"questions\"]\n",
        "}\n",
        "\n",
        "# Initialize objects based on schema\n",
        "def initialize_object_from_schema(schema):\n",
        "    if \"type\" not in schema:\n",
        "        return None\n",
        "\n",
        "    if schema[\"type\"] == \"object\":\n",
        "        obj = {}\n",
        "        for prop, prop_schema in schema.get(\"properties\", {}).items():\n",
        "            obj[prop] = initialize_object_from_schema(prop_schema)\n",
        "        return obj\n",
        "\n",
        "    elif schema[\"type\"] == \"array\":\n",
        "        return []\n",
        "\n",
        "    elif schema[\"type\"] == \"string\":\n",
        "        return \"\"\n",
        "\n",
        "    elif schema[\"type\"] == \"integer\":\n",
        "        return 0\n",
        "\n",
        "    elif schema[\"type\"] == \"number\":\n",
        "        return 0.0\n",
        "\n",
        "    elif schema[\"type\"] == \"boolean\":\n",
        "        return False\n",
        "\n",
        "    elif schema[\"type\"] == \"null\":\n",
        "        return None\n",
        "\n",
        "    return None\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "biEmX3CKxJdS",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title LLM utilities\n",
        "import os\n",
        "import torch\n",
        "from langchain import HuggingFacePipeline\n",
        "from transformers import BitsAndBytesConfig, AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "\n",
        "def load_llm_model(model_id=\"mistralai/Mistral-7B-Instruct-v0.1\", use_quantization=True):\n",
        "    print(model_id)\n",
        "    quantization_config = None\n",
        "\n",
        "    if use_quantization:\n",
        "        quantization_config = BitsAndBytesConfig(\n",
        "            load_in_4bit=True,\n",
        "            bnb_4bit_compute_dtype=torch.float16,\n",
        "            bnb_4bit_quant_type=\"nf4\",\n",
        "            bnb_4bit_use_double_quant=True,\n",
        "        )\n",
        "\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_id,\n",
        "        device_map=\"auto\",\n",
        "        offload_folder=\"/tmp\",\n",
        "        quantization_config=quantization_config,\n",
        "        trust_remote_code=True\n",
        "    )\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
        "\n",
        "    return model, tokenizer\n",
        "\n",
        "def setup_llm_pipeline(model, tokenizer):\n",
        "    pp = pipeline(\n",
        "        \"text-generation\",\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        use_cache=True,\n",
        "        device_map=\"auto\",\n",
        "        max_length=3000,\n",
        "        do_sample=True,\n",
        "        top_k=5,\n",
        "        num_return_sequences=1,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "    )\n",
        "    return HuggingFacePipeline(pipeline=pp)\n",
        "\n",
        "def unload_llm_model(model):\n",
        "    del model\n",
        "    torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Constants\n",
        "#### Prompt\n",
        "short_answer_template = \"\"\"[INST]Please read the following context and answer the question at the end. Start with `Answer:` followed by the answer. The answer should be very short.\n",
        "Example Output:\n",
        "Answer: Glaucoma.\n",
        "[/INST]\n",
        "\n",
        "Context: {context}\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "\n",
        "two_part_template = \"\"\"[INST]Please read the following context and answer the question at the end. Start with `Answer:` followed by 'Yes' or 'No,' and then write `Justification:` followed by your reasoning.\n",
        "Example Output:\n",
        "Answer: Yes\n",
        "Justification: The evidence in the context strongly supports a 'Yes' answer.\n",
        "[/INST]\n",
        "\n",
        "Context: {context}\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "\n",
        "assessement_template = \"\"\"[INST]Please read the following doctor treatment plan and classify it. The categories are \"mild\", \"average\", \"aggressive\".\n",
        "Example of a good answer: \"Answer: mild\".[/INST]\n",
        "Context: {context}\n",
        "\"\"\"\n",
        "\n",
        "base_questions = {\n",
        "  \"chief_complaint\": \"What is the patient main complaint?\",\n",
        "  \"treatment_plan\": \"what treatment plan is the doctor suggesting?\",\n",
        "  \"allergies\":\"Does the patient have allergies and if so, which ones?\",\n",
        "  \"preexisting_medications\":\"Is the patient on medications?\"\n",
        "}\n",
        "\n",
        "specific_questions = [\n",
        "  \"Does the patient have a family history of colon cancer in their first-degree relatives?\",\n",
        "  \"Has the patient experienced minimal bright red blood per rectum?\",\n",
        "  \"Has the patient had significant loss of blood?\"\n",
        "  \"Does the patient have a history of skin problems?\",\n",
        "  \"Has the patient used hydrocortisone cream for the haemorrhoids that they are recently experiencing?\",\n",
        "  \"Were any high risk traits found on the patient’s genetic test?\",\n",
        "  \"Has the patient had a colonoscopy in the last 5 years?\",\n",
        "  \"Has the patient had any recent foreign travel?\",\n",
        "  \"How long has the patient been known to healthcare services?\"\n",
        "]\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "UhFggdnPw--s"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DL0j5qlCJfjC",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Analyse Document\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "\n",
        "def extract_answer_and_justification(text):\n",
        "    answer_pattern = r\"Answer: (Yes|No)\"\n",
        "    justification_pattern = r\"Justification: (.+)\"\n",
        "\n",
        "    answer_match = re.search(answer_pattern, text)\n",
        "    justification_match = re.search(justification_pattern, text)\n",
        "\n",
        "    answer = \"Default Answer\"  # Default value for answer\n",
        "    justification = \"Default Justification\"  # Default value for justification\n",
        "\n",
        "    if answer_match:\n",
        "        answer = answer_match.group(1)\n",
        "\n",
        "    if justification_match:\n",
        "        justification = justification_match.group(1)\n",
        "\n",
        "    return answer, justification\n",
        "\n",
        "\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "\n",
        "def analyse_document(llm, initial_object, base_questions, specific_questions, context_p):\n",
        "\n",
        "    print(initial_object)\n",
        "\n",
        "    for key, question in tqdm(base_questions.items(), desc=\"Extracting general info..\"):\n",
        "\n",
        "      prompt = PromptTemplate(template=short_answer_template, input_variables=[\"question\",\"context\"])\n",
        "      llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
        "\n",
        "      response = llm_chain.run({\"question\":question,\"context\":context_p})\n",
        "      initial_object[\"general_info\"][key] = response.lstrip('Answer:')\n",
        "\n",
        "      if key == \"treatment_plan\":\n",
        "        prompt = PromptTemplate(template=assessement_template, input_variables=[\"context\"])\n",
        "        llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
        "        response = llm_chain.run({\"context\": response})\n",
        "\n",
        "        initial_object[\"general_info\"][\"meta\"][\"treatment_assessment\"] = response.lstrip('Answer:')\n",
        "\n",
        "\n",
        "\n",
        "    for question in tqdm(specific_questions, desc=\"Answering questions..\"):\n",
        "      question_item = initialize_object_from_schema(question_schema)\n",
        "\n",
        "      prompt = PromptTemplate(template=two_part_template, input_variables=[\"question\",\"context\"])\n",
        "      llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
        "\n",
        "      response_text = llm_chain.run({\"question\":question,\"context\":context_p})\n",
        "\n",
        "      answer, justification = extract_answer_and_justification(response_text)\n",
        "\n",
        "      question_item[\"answer\"] = answer.lstrip('Answer:')\n",
        "      question_item[\"justification\"] = justification.lstrip('Answer:')\n",
        "      question_item[\"question\"] = question\n",
        "\n",
        "      initial_object[\"questions\"].append(question_item)\n",
        "\n",
        "\n",
        "\n",
        "    return initial_object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9tLlgE2BU_Rx",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Confidence scoring\n",
        "import torch\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "\n",
        "from functools import partial\n",
        "\n",
        "\n",
        "def load_model_and_tokenizer(questions_list):\n",
        "    global model, tokenizer\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "    model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "    return questions_list\n",
        "\n",
        "def unload_model_and_tokenizer(questions_list):\n",
        "    global model, tokenizer\n",
        "    del model\n",
        "    del tokenizer\n",
        "    model = None\n",
        "    tokenizer = None\n",
        "    torch.cuda.empty_cache()\n",
        "    return questions_list\n",
        "\n",
        "def calculate_and_normalize_perplexity(questions_list):\n",
        "    if model is None or tokenizer is None:\n",
        "        print(\"Model and tokenizer are not loaded. Please load them first.\")\n",
        "        return\n",
        "\n",
        "    for item in questions_list:\n",
        "      if not isinstance(item, dict):\n",
        "        print(f\"Skipping item {item} because it's not a dictionary\")\n",
        "        continue\n",
        "\n",
        "      if \"question\" not in item or \"justification\" not in item:\n",
        "        print(f\"Skipping item {item} because it lacks required keys\")\n",
        "        continue\n",
        "\n",
        "      question = item[\"question\"]\n",
        "      justification = item[\"justification\"]\n",
        "\n",
        "      text = question + \" \" + justification\n",
        "      input_ids = tokenizer.encode(text, return_tensors=\"pt\")\n",
        "\n",
        "      with torch.no_grad():\n",
        "          output = model(input_ids, labels=input_ids)\n",
        "          log_likelihood = output.loss\n",
        "\n",
        "      perplexity = torch.exp(log_likelihood).item()\n",
        "\n",
        "      # Normalize perplexity\n",
        "      max_perplexity = 500\n",
        "      perplexity = min(max(perplexity, 1), max_perplexity)\n",
        "      normalized_score = 1 + 9 * ((perplexity - 1) / (max_perplexity - 1))\n",
        "      inverted_score = 11 - normalized_score\n",
        "\n",
        "        # Update confidence_score\n",
        "      item[\"confidence_score\"] = int(round(inverted_score))\n",
        "\n",
        "    return questions_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "v2hGK5uoBvmE",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Utils\n",
        "# Function to convert data to JSON and validate\n",
        "def convert_to_json_and_validate(data, schema):\n",
        "    json_data = json.dumps(data)\n",
        "\n",
        "    try:\n",
        "        validate(instance=data, schema=schema)\n",
        "        print(\"JSON data is valid.\")\n",
        "    except Exception as e:\n",
        "        print(f\"JSON data is invalid: {e}\")\n",
        "\n",
        "    return json_data\n",
        "\n",
        "def categorize_risk(data):\n",
        "  total_questions = len(data.get('questions', []))\n",
        "  one_third = total_questions / 3\n",
        "  two_thirds = 2 * one_third\n",
        "\n",
        "  count = 0\n",
        "  for question in data.get('questions', []):\n",
        "      answer = question.get('answer', '').strip().lower()\n",
        "      if answer == 'yes':\n",
        "          count += 1\n",
        "\n",
        "  if count < one_third:\n",
        "      return 'Low'\n",
        "  elif count < two_thirds:\n",
        "      return 'Average'\n",
        "  else:\n",
        "      return 'High'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "X3Q9-dhSCyUE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a37f15eb36eb4789980cab538b488445",
            "02a694d8663c43b3b5ca4fc860c4838b",
            "072a65897672405b9380288b3df1c3d4",
            "b708040f0e18430ab5837e02c36b02e1",
            "96bdc99216d94a198c5b80a652ab636d",
            "aa626a797bc94f6f90f4f0595f622625",
            "2554c936c0b945c5b1b698822ed8ace7",
            "7685795f6434428d95fbad8388654bea",
            "c22f0f324adb415093fba15f72c3d189",
            "aee5d263e69847fb8e7488d4226eda1a",
            "7e27635467804b9fbc973db27c41b02c"
          ]
        },
        "outputId": "4d2656cf-01cf-407b-caee-2d208f891582"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mistralai/Mistral-7B-Instruct-v0.1\n",
            "\n",
            "===================================BUG REPORT===================================\n",
            "Welcome to bitsandbytes. For bug reports, please run\n",
            "\n",
            "python -m bitsandbytes\n",
            "\n",
            " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
            "================================================================================\n",
            "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
            "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
            "CUDA SETUP: Highest compute capability among GPUs detected: 7.0\n",
            "CUDA SETUP: Detected CUDA version 118\n",
            "CUDA SETUP: Loading binary /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cuda118_nocublaslt.so...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:147: UserWarning: /usr/lib64-nvidia did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:147: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/sys/fs/cgroup/memory.events /var/colab/cgroup/jupyter-children/memory.events')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:147: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//172.28.0.1'), PosixPath('http'), PosixPath('8013')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:147: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//colab.research.google.com/tun/m/cc48301118ce562b961b3c22d803539adc1e0c19/gpu-v100-hm-2qbgsphl2kl3o --tunnel_background_save_delay=10s --tunnel_periodic_background_save_frequency=30m0s --enable_output_coalescing=true --output_coalescing_required=true'), PosixPath('--logtostderr --listen_host=172.28.0.12 --target_host=172.28.0.12 --tunnel_background_save_url=https')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:147: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/env/python')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:147: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//ipykernel.pylab.backend_inline'), PosixPath('module')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:147: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so'), PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
            "Either way, this might cause trouble in the future:\n",
            "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:147: UserWarning: WARNING: Compute capability < 7.5 detected! Only slow 8-bit matmul is supported for your GPU!\n",
            "  warn(msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a37f15eb36eb4789980cab538b488445"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'general_info': {'chief_complaint': '', 'allergies': '', 'preexisting_medications': '', 'meta': {'risk_profile': '', 'treatment_assessment': ''}}, 'questions': []}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting general info..: 100%|██████████| 4/4 [00:30<00:00,  7.57s/it]\n",
            "Answering questions..:  62%|██████▎   | 5/8 [00:21<00:12,  4.15s/it]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "Answering questions..: 100%|██████████| 8/8 [00:41<00:00,  5.17s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JSON data is valid.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'general_info': {'chief_complaint': ' Hemorrhoids.',\n",
              "  'allergies': '\\nAnswer: None mentioned in the medical record. However, it should be noted that allergies are not reviewed in the context provided.',\n",
              "  'preexisting_medications': ' Yes',\n",
              "  'meta': {'risk_profile': 'Average',\n",
              "   'treatment_assessment': \"\\nAnswer: aggressive\\n\\nThe treatment plan for hemorrhoids is banding procedure through colonoscopy, which is an aggressive approach to treat hemorrhoids. This procedure is typically reserved for severe cases of hemorrhoids and is recommended for patients who are experiencing significant bleeding or discomfort. The patient's family history of colon cancer and risk for developing malignant neoplasm of colon make them a higher risk for developing hemorrhoids and require further investigation. The patient should seek an evaluation for the banding procedure as soon as possible to prevent any potential complications that may arise from the bleeding.\"},\n",
              "  'treatment_plan': ' Treatment plan for hemorrhoids is banding procedure through colonoscopy. The patient has a family history of colon cancer and is at risk for developing malignant neoplasm of colon. The patient is also having bleeding and may require further investigation with colonoscopy. The patient is advised to seek an evaluation for banding procedure. Additionally, the patient is at risk for developing hemorrhoids due to a family history of colon cancer and may require further investigation with colonoscopy. The patient is advised to seek an evaluation for banding procedure.'},\n",
              " 'questions': [{'question': 'Does the patient have a family history of colon cancer in their first-degree relatives?',\n",
              "   'answer': 'Yes',\n",
              "   'justification': 'The patient has a family history of colon cancer in their first-degree relatives (grandfather on their eighth degree).',\n",
              "   'confidence_score': 10},\n",
              "  {'question': 'Has the patient experienced minimal bright red blood per rectum?',\n",
              "   'answer': 'Yes',\n",
              "   'justification': 'Default Justification',\n",
              "   'confidence_score': 1},\n",
              "  {'question': 'Has the patient had significant loss of blood?Does the patient have a history of skin problems?',\n",
              "   'answer': 'Default Answer',\n",
              "   'justification': 'No. The patient does not report any history of skin problems.',\n",
              "   'confidence_score': 10},\n",
              "  {'question': 'Has the patient used hydrocortisone cream for the haemorrhoids that they are recently experiencing?',\n",
              "   'answer': 'Yes',\n",
              "   'justification': 'Default Justification',\n",
              "   'confidence_score': 9},\n",
              "  {'question': 'Were any high risk traits found on the patient’s genetic test?',\n",
              "   'answer': 'Yes',\n",
              "   'justification': 'The patient has a family history of colon cancer, which is a high risk trait. Therefore, the patient’s genetic test should be reviewed to identify any other high risk traits that may increase the risk for colon cancer.',\n",
              "   'confidence_score': 10},\n",
              "  {'question': 'Has the patient had a colonoscopy in the last 5 years?',\n",
              "   'answer': 'No',\n",
              "   'justification': \"The patient's family history of colon cancer and lack of colonoscopy indicate a need for a colonoscopy to rule out malignancy. Additionally, the patient's BRBPR last year indicates a need for further evaluation.\",\n",
              "   'confidence_score': 10},\n",
              "  {'question': 'Has the patient had any recent foreign travel?',\n",
              "   'answer': 'Default Answer',\n",
              "   'justification': 'Default Justification',\n",
              "   'confidence_score': 3},\n",
              "  {'question': 'How long has the patient been known to healthcare services?',\n",
              "   'answer': 'Yes',\n",
              "   'justification': 'Default Justification',\n",
              "   'confidence_score': 4}]}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "#@title Main\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "def main_pipeline(\n",
        "    medical_text: str,\n",
        "    schema: Dict[str, Any],\n",
        "    base_questions: List[Dict[str, Any]],\n",
        "    specific_questions: List[Dict[str, Any]]\n",
        ") -> Dict[str, Any]:\n",
        "    try:\n",
        "        use_quantization = not os.environ.get(\"DISABLE_QUANTIZATION\", False)\n",
        "\n",
        "        model_id_1 = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
        "\n",
        "        # Initialize DTO from schema\n",
        "        dto = initialize_object_from_schema(schema)\n",
        "\n",
        "        # Load first LLM model and analyze document\n",
        "        model, tokenizer = load_llm_model(model_id_1, use_quantization=use_quantization)\n",
        "        llm = setup_llm_pipeline(model, tokenizer)\n",
        "        dto = analyse_document(llm, dto, base_questions, specific_questions, medical_text)\n",
        "\n",
        "        confidence = calculate_and_normalize_perplexity(load_model_and_tokenizer(dto[\"questions\"]))\n",
        "        dto[\"questions\"] = confidence\n",
        "\n",
        "        unload_llm_model(model)\n",
        "\n",
        "\n",
        "        dto[\"general_info\"][\"meta\"][\"risk_profile\"] = categorize_risk(dto)\n",
        "\n",
        "        return convert_to_json_and_validate(dto, schema)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return {}\n",
        "\n",
        "\n",
        "# Run the pipeline\n",
        "result = main_pipeline(medical_text, schema, base_questions, specific_questions)\n",
        "\n",
        "json.loads(result)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a37f15eb36eb4789980cab538b488445": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_02a694d8663c43b3b5ca4fc860c4838b",
              "IPY_MODEL_072a65897672405b9380288b3df1c3d4",
              "IPY_MODEL_b708040f0e18430ab5837e02c36b02e1"
            ],
            "layout": "IPY_MODEL_96bdc99216d94a198c5b80a652ab636d"
          }
        },
        "02a694d8663c43b3b5ca4fc860c4838b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa626a797bc94f6f90f4f0595f622625",
            "placeholder": "​",
            "style": "IPY_MODEL_2554c936c0b945c5b1b698822ed8ace7",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "072a65897672405b9380288b3df1c3d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7685795f6434428d95fbad8388654bea",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c22f0f324adb415093fba15f72c3d189",
            "value": 2
          }
        },
        "b708040f0e18430ab5837e02c36b02e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aee5d263e69847fb8e7488d4226eda1a",
            "placeholder": "​",
            "style": "IPY_MODEL_7e27635467804b9fbc973db27c41b02c",
            "value": " 2/2 [00:16&lt;00:00,  7.56s/it]"
          }
        },
        "96bdc99216d94a198c5b80a652ab636d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa626a797bc94f6f90f4f0595f622625": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2554c936c0b945c5b1b698822ed8ace7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7685795f6434428d95fbad8388654bea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c22f0f324adb415093fba15f72c3d189": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aee5d263e69847fb8e7488d4226eda1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e27635467804b9fbc973db27c41b02c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}